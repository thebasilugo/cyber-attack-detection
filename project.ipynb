{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1aa8e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### PATHWAY: ###\n",
    "    # Print to show progress\n",
    "\n",
    "# 1. Load and preprocess the data:\n",
    "    # 1a. Data Collection: The data collection is a process of collecting relevant data for their work. The job of this process is to collect and analyze the data whether the data needed for their work. Herewe collected the unsw nb15 network intrusion dataset from uci.edu.\n",
    "    # 1b. Data Visualization: The purpose of visualization is for easy understanding. visualization can be shown in graphs, diagrams, slides, etc. Here we represent the graph. It shows the intrusion accuracy of the learning model which we have used.\n",
    "    # 1c. Import necessary libraries.\n",
    "    # 1d. Load the UNSW-NB15 dataset into Jupyter Notebooks\n",
    "    # 1e. Data Preprocessing: The purpose of preprocessing is to convert the raw data into the form that ﬁts for machine learning models. For data preprocessing the data will be normalized and categorical features converted into numerical form by data encoding method.\n",
    "        # 1ei. Preprocess the data by performing feature scaling, normalization, and one-hot encoding as necessary. \n",
    "    # 1f. 4.2.4. Dataset Splitting: After preprocessing the dataset will be splitted into training and testing data. Training data is modeled into a form of algorithm ﬁt. Testing data is used to evaluate the training data. \n",
    "        # 1fi. Split the dataset into training, validation, and testing sets as per your requirement.\n",
    "        # 1fii. Reformat the training to NOT have the target, and the testing to have ONLY the target\n",
    "\n",
    "# 2. Feature Selection: \n",
    "    # 2a. Use the exhaustive feature selection algorithm to select the most relevant features from the training dataset. \n",
    "    # 2b. Use libraries such as scikit-learn to perform feature selection.\n",
    "\n",
    "# 3. Dimensionality Reduction: \n",
    "    # 3a. Use linear discriminant analysis to reduce the dimensionality of the selected features. \n",
    "    # 3b. Again, use scikit-learn for this step.\n",
    "\n",
    "# 4. Model Creation and Training: \n",
    "    # 4a. Model Training: After preprocessing and data will be splitted into training and testing data. A deep learning model is applied to the training data and we will get a trained model.\n",
    "        # 4ai. Create and train the hybrid CNN-MLP models using the reduced feature set. \n",
    "    # 4b. Use libraries such as TensorFlow or PyTorch to create and train your models.\n",
    "\n",
    "# 5. Model Evaluation: \n",
    "    # 5a. Model Evaluation: We will compare the trained model with testing data and determine the accuracy of the deep learning model. Evaluation metrics will be evaluated to ﬁnd the performance of the algorithm. Here we used MSE, MAE, R-Square, RMSE for evaluation metrics.\n",
    "    # 5ai. Evaluate the performance of the trained models on the validation dataset by calculating metrics such as accuracy, precision, recall, and F1-score. \n",
    "    # 5aii. Tweak the model hyperparameters and architecture as necessary to improve performance.\n",
    "\n",
    "# 6. Testing: \n",
    "    # 6a. Test the best performing model on the testing dataset and report its performance.\n",
    "\n",
    "# 7. Comparison: \n",
    "    # 7a. Perform a training on singular MLP and CNN, and record its performance\n",
    "    # 7b. Compare the performance with the hybrid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16c5a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 10:08:56.176707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 10:08:57.869065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-02 10:08:57.869110: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-02 10:09:01.305548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 10:09:01.305704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 10:09:01.305720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1c\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print('Done 1c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9acb770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: (82332, 45)\n",
      "Cleaned: (82332, 45)\n",
      "Done 1d\n"
     ]
    }
   ],
   "source": [
    "# Read the datasets into a pandas DataFrame\n",
    "df = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "print('Normal:', df.shape)\n",
    "\n",
    "# Clean the data\n",
    "df = df.dropna()\n",
    "print('Cleaned:', df.shape)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done 1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e25f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id       dur  spkts  dpkts  sbytes  dbytes           rate  sttl  \\\n",
      "0          1  0.000011      2      0     496       0   90909.090200   254   \n",
      "1          2  0.000008      2      0    1762       0  125000.000300   254   \n",
      "2          3  0.000005      2      0    1068       0  200000.005100   254   \n",
      "3          4  0.000006      2      0     900       0  166666.660800   254   \n",
      "4          5  0.000010      2      0    2126       0  100000.002500   254   \n",
      "...      ...       ...    ...    ...     ...     ...            ...   ...   \n",
      "82327  82328  0.000005      2      0     104       0  200000.005100   254   \n",
      "82328  82329  1.106101     20      8   18062     354      24.410067   254   \n",
      "82329  82330  0.000000      1      0      46       0       0.000000     0   \n",
      "82330  82331  0.000000      1      0      46       0       0.000000     0   \n",
      "82331  82332  0.000009      2      0     104       0  111111.107200   254   \n",
      "\n",
      "       dttl         sload  ...  attack_cat_Analysis  attack_cat_Backdoor  \\\n",
      "0         0  1.803636e+08  ...                    0                    0   \n",
      "1         0  8.810000e+08  ...                    0                    0   \n",
      "2         0  8.544000e+08  ...                    0                    0   \n",
      "3         0  6.000000e+08  ...                    0                    0   \n",
      "4         0  8.504000e+08  ...                    0                    0   \n",
      "...     ...           ...  ...                  ...                  ...   \n",
      "82327     0  8.320000e+07  ...                    0                    0   \n",
      "82328   252  1.241044e+05  ...                    0                    0   \n",
      "82329     0  0.000000e+00  ...                    0                    0   \n",
      "82330     0  0.000000e+00  ...                    0                    0   \n",
      "82331     0  4.622222e+07  ...                    0                    0   \n",
      "\n",
      "       attack_cat_DoS  attack_cat_Exploits  attack_cat_Fuzzers  \\\n",
      "0                   0                    0                   0   \n",
      "1                   0                    0                   0   \n",
      "2                   0                    0                   0   \n",
      "3                   0                    0                   0   \n",
      "4                   0                    0                   0   \n",
      "...               ...                  ...                 ...   \n",
      "82327               0                    0                   0   \n",
      "82328               0                    0                   0   \n",
      "82329               0                    0                   0   \n",
      "82330               0                    0                   0   \n",
      "82331               0                    0                   0   \n",
      "\n",
      "       attack_cat_Generic  attack_cat_Normal  attack_cat_Reconnaissance  \\\n",
      "0                       0                  1                          0   \n",
      "1                       0                  1                          0   \n",
      "2                       0                  1                          0   \n",
      "3                       0                  1                          0   \n",
      "4                       0                  1                          0   \n",
      "...                   ...                ...                        ...   \n",
      "82327                   0                  1                          0   \n",
      "82328                   0                  1                          0   \n",
      "82329                   0                  1                          0   \n",
      "82330                   0                  1                          0   \n",
      "82331                   0                  1                          0   \n",
      "\n",
      "       attack_cat_Shellcode  attack_cat_Worms  \n",
      "0                         0                 0  \n",
      "1                         0                 0  \n",
      "2                         0                 0  \n",
      "3                         0                 0  \n",
      "4                         0                 0  \n",
      "...                     ...               ...  \n",
      "82327                     0                 0  \n",
      "82328                     0                 0  \n",
      "82329                     0                 0  \n",
      "82330                     0                 0  \n",
      "82331                     0                 0  \n",
      "\n",
      "[82332 rows x 201 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "82327    0\n",
      "82328    0\n",
      "82329    0\n",
      "82330    0\n",
      "82331    0\n",
      "Name: label, Length: 82332, dtype: int64\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['label']\n",
    "\n",
    "# Find out the use of .values\n",
    "\n",
    "# Convert categorical features to one-hot encoded columns\n",
    "X = pd.get_dummies(df.drop('label', axis=1))\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269a1b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.73202977 -0.21372745 -0.1244551  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]\n",
      " [-1.7319877  -0.21372808 -0.1244551  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]\n",
      " [-1.73194562 -0.21372872 -0.1244551  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]\n",
      " ...\n",
      " [ 1.73194562 -0.21372978 -0.1319225  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]\n",
      " [ 1.7319877  -0.21372978 -0.1319225  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]\n",
      " [ 1.73202977 -0.21372787 -0.1244551  ... -0.21058305 -0.06791424\n",
      "  -0.02312374]]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the feature matrix\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9a20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "          id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0          1  0.000011   udp       -   INT      2      0     496       0   \n",
      "1          2  0.000008   udp       -   INT      2      0    1762       0   \n",
      "2          3  0.000005   udp       -   INT      2      0    1068       0   \n",
      "3          4  0.000006   udp       -   INT      2      0     900       0   \n",
      "4          5  0.000010   udp       -   INT      2      0    2126       0   \n",
      "...      ...       ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "82327  82328  0.000005   udp       -   INT      2      0     104       0   \n",
      "82328  82329  1.106101   tcp       -   FIN     20      8   18062     354   \n",
      "82329  82330  0.000000   arp       -   INT      1      0      46       0   \n",
      "82330  82331  0.000000   arp       -   INT      1      0      46       0   \n",
      "82331  82332  0.000009   udp       -   INT      2      0     104       0   \n",
      "\n",
      "                rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0       90909.090200  ...                 1               2             0   \n",
      "1      125000.000300  ...                 1               2             0   \n",
      "2      200000.005100  ...                 1               3             0   \n",
      "3      166666.660800  ...                 1               3             0   \n",
      "4      100000.002500  ...                 1               3             0   \n",
      "...              ...  ...               ...             ...           ...   \n",
      "82327  200000.005100  ...                 1               2             0   \n",
      "82328      24.410067  ...                 1               1             0   \n",
      "82329       0.000000  ...                 1               1             0   \n",
      "82330       0.000000  ...                 1               1             0   \n",
      "82331  111111.107200  ...                 1               1             0   \n",
      "\n",
      "       ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0               0                 0           1           2                0   \n",
      "1               0                 0           1           2                0   \n",
      "2               0                 0           1           3                0   \n",
      "3               0                 0           2           3                0   \n",
      "4               0                 0           2           3                0   \n",
      "...           ...               ...         ...         ...              ...   \n",
      "82327           0                 0           2           1                0   \n",
      "82328           0                 0           3           2                0   \n",
      "82329           0                 0           1           1                1   \n",
      "82330           0                 0           1           1                1   \n",
      "82331           0                 0           1           1                0   \n",
      "\n",
      "       attack_cat  label  \n",
      "0          Normal      0  \n",
      "1          Normal      0  \n",
      "2          Normal      0  \n",
      "3          Normal      0  \n",
      "4          Normal      0  \n",
      "...           ...    ...  \n",
      "82327      Normal      0  \n",
      "82328      Normal      0  \n",
      "82329      Normal      0  \n",
      "82330      Normal      0  \n",
      "82331      Normal      0  \n",
      "\n",
      "[82332 rows x 45 columns]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Identify and remove duplicates from dataset:\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print(df)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92fa9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Frame\n",
      "id                   0\n",
      "dur                  0\n",
      "proto                0\n",
      "service              0\n",
      "state                0\n",
      "spkts                0\n",
      "dpkts                0\n",
      "sbytes               0\n",
      "dbytes               0\n",
      "rate                 0\n",
      "sttl                 0\n",
      "dttl                 0\n",
      "sload                0\n",
      "dload                0\n",
      "sloss                0\n",
      "dloss                0\n",
      "sinpkt               0\n",
      "dinpkt               0\n",
      "sjit                 0\n",
      "djit                 0\n",
      "swin                 0\n",
      "stcpb                0\n",
      "dtcpb                0\n",
      "dwin                 0\n",
      "tcprtt               0\n",
      "synack               0\n",
      "ackdat               0\n",
      "smean                0\n",
      "dmean                0\n",
      "trans_depth          0\n",
      "response_body_len    0\n",
      "ct_srv_src           0\n",
      "ct_state_ttl         0\n",
      "ct_dst_ltm           0\n",
      "ct_src_dport_ltm     0\n",
      "ct_dst_sport_ltm     0\n",
      "ct_dst_src_ltm       0\n",
      "is_ftp_login         0\n",
      "ct_ftp_cmd           0\n",
      "ct_flw_http_mthd     0\n",
      "ct_src_ltm           0\n",
      "ct_srv_dst           0\n",
      "is_sm_ips_ports      0\n",
      "attack_cat           0\n",
      "label                0\n",
      "dtype: int64\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Training Data Frame\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\")\n",
    "\n",
    "# Drop rows with missing values (Not necessary)\n",
    "# df_train.dropna(inplace=True)\n",
    "\n",
    "# Fill missing values (Not necessary)\n",
    "# df_train.fillna(0, inplace=True)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75cff1f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82332, 45)\n",
      "<bound method NDFrame.head of           id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0          1  0.000011    117        0      4      2      0     496       0   \n",
      "1          2  0.000008    117        0      4      2      0    1762       0   \n",
      "2          3  0.000005    117        0      4      2      0    1068       0   \n",
      "3          4  0.000006    117        0      4      2      0     900       0   \n",
      "4          5  0.000010    117        0      4      2      0    2126       0   \n",
      "...      ...       ...    ...      ...    ...    ...    ...     ...     ...   \n",
      "82327  82328  0.000005    117        0      4      2      0     104       0   \n",
      "82328  82329  1.106101    111        0      3     20      8   18062     354   \n",
      "82329  82330  0.000000      6        0      4      1      0      46       0   \n",
      "82330  82331  0.000000      6        0      4      1      0      46       0   \n",
      "82331  82332  0.000009    117        0      4      2      0     104       0   \n",
      "\n",
      "                rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0       90909.090200  ...                 1               2             0   \n",
      "1      125000.000300  ...                 1               2             0   \n",
      "2      200000.005100  ...                 1               3             0   \n",
      "3      166666.660800  ...                 1               3             0   \n",
      "4      100000.002500  ...                 1               3             0   \n",
      "...              ...  ...               ...             ...           ...   \n",
      "82327  200000.005100  ...                 1               2             0   \n",
      "82328      24.410067  ...                 1               1             0   \n",
      "82329       0.000000  ...                 1               1             0   \n",
      "82330       0.000000  ...                 1               1             0   \n",
      "82331  111111.107200  ...                 1               1             0   \n",
      "\n",
      "       ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0               0                 0           1           2                0   \n",
      "1               0                 0           1           2                0   \n",
      "2               0                 0           1           3                0   \n",
      "3               0                 0           2           3                0   \n",
      "4               0                 0           2           3                0   \n",
      "...           ...               ...         ...         ...              ...   \n",
      "82327           0                 0           2           1                0   \n",
      "82328           0                 0           3           2                0   \n",
      "82329           0                 0           1           1                1   \n",
      "82330           0                 0           1           1                1   \n",
      "82331           0                 0           1           1                0   \n",
      "\n",
      "       attack_cat  label  \n",
      "0               6      0  \n",
      "1               6      0  \n",
      "2               6      0  \n",
      "3               6      0  \n",
      "4               6      0  \n",
      "...           ...    ...  \n",
      "82327           6      0  \n",
      "82328           6      0  \n",
      "82329           6      0  \n",
      "82330           6      0  \n",
      "82331           6      0  \n",
      "\n",
      "[82332 rows x 45 columns]>\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Encoding of Categorical columns into numerical columns\n",
    "\n",
    "# ONE-HOT ENCODER\n",
    "# select all categorical columns\n",
    "# categorical_cols = ['proto', 'state', 'service', 'is_sm_ips_ports', 'ct_ftp_cmd', 'ct_src_dport_ltm', 'ct_dst_ltm', 'ct_src_ltm',\n",
    "#             'ct_srv_dst', 'ct_flw_http_mthd', 'ct_srv_src', 'is_ftp_login', 'attack_cat']\n",
    "# # numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# # encoder = LabelEncoder()\n",
    "# # for col in categorical_cols:\n",
    "# #     X[col] = encoder.fit_transform(X[col])\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "# # perform one-hot encoding\n",
    "# df_encoded_train = pd.get_dummies(df_train, columns=categorical_cols)\n",
    "\n",
    "# # display the encoded dataframe\n",
    "# print(df_encoded_train.head())\n",
    "\n",
    "#LABEL_ENCODER\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['proto'] = label_encoder.fit_transform(df['proto'])\n",
    "df['state'] = label_encoder.fit_transform(df['state'])\n",
    "df['service'] = label_encoder.fit_transform(df['service'])\n",
    "df['attack_cat'] = label_encoder.fit_transform(df['attack_cat'])\n",
    "print(df.shape)\n",
    "print(df.head)\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e794c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Dropping Irrelevant columns in the dataset\n",
    "\n",
    "# # Drop irrelevant columns\n",
    "# df_train.drop(['id', 'proto', 'service', 'state', 'attack_cat'], axis=1, inplace=True)\n",
    "\n",
    "# # Save cleaned training dataset\n",
    "# df_train.to_csv('UNSW_NB15_training-set_cleaned.csv', index=False)\n",
    "\n",
    "# # Read in testing dataset\n",
    "# df_test = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# # Drop irrelevant columns\n",
    "# df_test.drop(['id', 'proto', 'service', 'state'], axis=1, inplace=True)\n",
    "\n",
    "# # Save cleaned testing dataset\n",
    "# df_test.to_csv('UNSW_NB15_testing-set_cleaned.csv', index=False)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2d65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id       dur  proto  service  state     spkts     dpkts    sbytes  \\\n",
      "0          1 -0.213727    117        0      4 -0.124455 -0.151816 -0.043684   \n",
      "1          2 -0.213728    117        0      4 -0.124455 -0.151816 -0.036308   \n",
      "2          3 -0.213729    117        0      4 -0.124455 -0.151816 -0.040351   \n",
      "3          4 -0.213729    117        0      4 -0.124455 -0.151816 -0.041330   \n",
      "4          5 -0.213728    117        0      4 -0.124455 -0.151816 -0.034187   \n",
      "...      ...       ...    ...      ...    ...       ...       ...       ...   \n",
      "82327  82328 -0.213729    117        0      4 -0.124455 -0.151816 -0.045967   \n",
      "82328  82329  0.021090    111        0      3  0.009958 -0.082596  0.058658   \n",
      "82329  82330 -0.213730      6        0      4 -0.131922 -0.151816 -0.046305   \n",
      "82330  82331 -0.213730      6        0      4 -0.131922 -0.151816 -0.046305   \n",
      "82331  82332 -0.213728    117        0      4 -0.124455 -0.151816 -0.045967   \n",
      "\n",
      "         dbytes      rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0     -0.087369  0.057181  ...         -0.450186       -0.477994   \n",
      "1     -0.087369  0.286565  ...         -0.450186       -0.477994   \n",
      "2     -0.087369  0.791209  ...         -0.450186       -0.390391   \n",
      "3     -0.087369  0.566923  ...         -0.450186       -0.390391   \n",
      "4     -0.087369  0.118350  ...         -0.450186       -0.390391   \n",
      "...         ...       ...  ...               ...             ...   \n",
      "82327 -0.087369  0.791209  ...         -0.450186       -0.477994   \n",
      "82328 -0.085032 -0.554345  ...         -0.450186       -0.565597   \n",
      "82329 -0.087369 -0.554509  ...         -0.450186       -0.565597   \n",
      "82330 -0.087369 -0.554509  ...         -0.450186       -0.565597   \n",
      "82331 -0.087369  0.193112  ...         -0.450186       -0.565597   \n",
      "\n",
      "       is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
      "0                 0           0                 0           1           2   \n",
      "1                 0           0                 0           1           2   \n",
      "2                 0           0                 0           1           3   \n",
      "3                 0           0                 0           2           3   \n",
      "4                 0           0                 0           2           3   \n",
      "...             ...         ...               ...         ...         ...   \n",
      "82327             0           0                 0           2           1   \n",
      "82328             0           0                 0           3           2   \n",
      "82329             0           0                 0           1           1   \n",
      "82330             0           0                 0           1           1   \n",
      "82331             0           0                 0           1           1   \n",
      "\n",
      "       is_sm_ips_ports  attack_cat  label  \n",
      "0                    0           6      0  \n",
      "1                    0           6      0  \n",
      "2                    0           6      0  \n",
      "3                    0           6      0  \n",
      "4                    0           6      0  \n",
      "...                ...         ...    ...  \n",
      "82327                0           6      0  \n",
      "82328                0           6      0  \n",
      "82329                1           6      0  \n",
      "82330                1           6      0  \n",
      "82331                0           6      0  \n",
      "\n",
      "[82332 rows x 45 columns]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select columns to standardize\n",
    "# standardization should be applied only to the training set and then the same scaler should be used to transform the testing set\n",
    "cols_to_standardize = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm']\n",
    "\n",
    "# Standardize selected columns\n",
    "scaler = StandardScaler()\n",
    "df[cols_to_standardize] = scaler.fit_transform(df[cols_to_standardize])\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Print 'Done' when finished\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b996c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (65865, 45)\n",
      "Validation dataset shape: (8234, 45)\n",
      "Testing dataset shape: (8233, 45)\n",
      "Done 1f\n"
     ]
    }
   ],
   "source": [
    "# Splitting of Training dataset into train and test, and testing into test and val with sci-kit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training dataset into training and testing datasets, in ratio 8:2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    # Training dataset shape: (65865, 45)\n",
    "    # Testing dataset shape: (16467, 45)\n",
    "\n",
    "# Split testing dataset into testing and validation, in ratio 1:1\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "    # Testing dataset shape: (8233, 45)\n",
    "    # Validation dataset shape: (8234, 45)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training dataset shape:\", df_train.shape)\n",
    "print(\"Validation dataset shape:\", df_val.shape)\n",
    "print(\"Testing dataset shape:\", df_test.shape)\n",
    "\n",
    "print(\"Done 1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8f98fa7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "          id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
      "37396  37397  1.796887    111        9      3     52     42   37518    3380   \n",
      "45184  45185  2.004763    111        0      3    152     26  190546    1128   \n",
      "80313  80314  0.899487    111        5      3     10     10     804    1174   \n",
      "68939  68940  0.000003    111        0      5      2      0      90       0   \n",
      "26772  26773  0.009326    111        0      3     36     38    2334   16290   \n",
      "...      ...       ...    ...      ...    ...    ...    ...     ...     ...   \n",
      "6265    6266  0.263156    111        5      3     10      8     794    2884   \n",
      "54886  54887  1.960670    111        5      3    152     34  195881   11000   \n",
      "76820  76821  0.488035    111        0      3     10      6     534     268   \n",
      "860      861  1.211704    111        5      3     10      8     746     354   \n",
      "15795  15796  0.000003    117        2      4      2      0     114       0   \n",
      "\n",
      "                rate  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "37396      51.756175  ...                 1                 1               1   \n",
      "45184      88.289743  ...                 1                 1               1   \n",
      "80313      21.123151  ...                 2                 1               2   \n",
      "68939  333333.321500  ...                 1                 1              11   \n",
      "26772    7827.579008  ...                 1                 1               1   \n",
      "...              ...  ...               ...               ...             ...   \n",
      "6265       64.600466  ...                 1                 1               1   \n",
      "54886      94.355501  ...                 1                 1               1   \n",
      "76820      30.735501  ...                 1                 1               4   \n",
      "860        14.029829  ...                 1                 1               1   \n",
      "15795  333333.321500  ...                41                16              43   \n",
      "\n",
      "       is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
      "37396             0           0                 0           1           3   \n",
      "45184             0           0                 0           1           1   \n",
      "80313             0           0                 1           2           2   \n",
      "68939             0           0                 0           6          11   \n",
      "26772             0           0                 0           6           9   \n",
      "...             ...         ...               ...         ...         ...   \n",
      "6265              0           0                 1           6           1   \n",
      "54886             0           0                 0           2           1   \n",
      "76820             0           0                 0           1           4   \n",
      "860               0           0                 1           1           1   \n",
      "15795             0           0                 0          41          43   \n",
      "\n",
      "       is_sm_ips_ports  attack_cat  \n",
      "37396                0           6  \n",
      "45184                0           4  \n",
      "80313                0           6  \n",
      "68939                0           6  \n",
      "26772                0           6  \n",
      "...                ...         ...  \n",
      "6265                 0           2  \n",
      "54886                0           5  \n",
      "76820                0           6  \n",
      "860                  0           7  \n",
      "15795                0           5  \n",
      "\n",
      "[65865 rows x 44 columns]\n",
      "Validation\n",
      "          id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
      "43824  43825  1.864727    111        0      3     12     10    1044     862   \n",
      "71462  71463  0.262322    111        0      3     10      6     534     268   \n",
      "63585  63586  0.000010    117        2      4      2      0     114       0   \n",
      "59561  59562  0.000011    117        2      4      2      0     114       0   \n",
      "66625  66626  0.000009    117        0      4      2      0     104       0   \n",
      "...      ...       ...    ...      ...    ...    ...    ...     ...     ...   \n",
      "32296  32297  0.008971    111        0      3     36     38    2334   16290   \n",
      "54695  54696  0.995998    111        3      3     14     12     810     682   \n",
      "55516  55517  0.000003    117        2      4      2      0     114       0   \n",
      "80053  80054  0.836989    111        5      3     10      8     832    1072   \n",
      "27449  27450  0.010917    111        0      3     36     38    2334   16290   \n",
      "\n",
      "                rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "43824      11.261702  ...                 1               1             0   \n",
      "71462      57.181630  ...                 1               8             0   \n",
      "63585  100000.002500  ...                 3               7             0   \n",
      "59561   90909.090200  ...                 3               7             0   \n",
      "66625  111111.107200  ...                 1               3             0   \n",
      "...              ...  ...               ...             ...           ...   \n",
      "32296    8137.331319  ...                 1               1             0   \n",
      "54695      25.100451  ...                 1               1             0   \n",
      "55516  333333.321500  ...                 3               3             0   \n",
      "80053      20.310900  ...                 1               2             0   \n",
      "27449    6686.819004  ...                 1               4             0   \n",
      "\n",
      "       ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "43824           0                 0           1           2                0   \n",
      "71462           0                 0           2           8                0   \n",
      "63585           0                 0           7          14                0   \n",
      "59561           0                 0          11          13                0   \n",
      "66625           0                 0           2           3                0   \n",
      "...           ...               ...         ...         ...              ...   \n",
      "32296           0                 0           4           3                0   \n",
      "54695           0                 0           1           2                0   \n",
      "55516           0                 0           4          12                0   \n",
      "80053           0                 1           1           2                0   \n",
      "27449           0                 0           9           9                0   \n",
      "\n",
      "       attack_cat  label  \n",
      "43824           4      1  \n",
      "71462           6      0  \n",
      "63585           5      1  \n",
      "59561           5      1  \n",
      "66625           6      0  \n",
      "...           ...    ...  \n",
      "32296           6      0  \n",
      "54695           4      1  \n",
      "55516           5      1  \n",
      "80053           6      0  \n",
      "27449           6      0  \n",
      "\n",
      "[8234 rows x 45 columns]\n",
      "Test\n",
      "1fii\n"
     ]
    }
   ],
   "source": [
    "# df_train = df_train.iloc[:, 0:44]\n",
    "x = df_train.iloc[:, 0:44]\n",
    "print('Train')\n",
    "# print(df_train)\n",
    "print(x)\n",
    "\n",
    "\n",
    "print('Validation')\n",
    "# print(df_val)\n",
    "v = df_val\n",
    "print(v)\n",
    "\n",
    "# df_test = df_test.iloc[:, -1]\n",
    "print('Test')\n",
    "# print(df_test)\n",
    "y = df_test\n",
    "\n",
    "print('1fii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b629daf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Step 4: Initialize the estimator\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(clf)\n",
    "\n",
    "# Step 5: Initialize the ExhaustiveFeatureSelector object\n",
    "efs = ExhaustiveFeatureSelector(clf,\n",
    "                               min_features=5,\n",
    "                               max_features=len(x.columns),\n",
    "                               scoring='accuracy',\n",
    "                               cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                               print_progress=True)\n",
    "\n",
    "# # Step 6: Fit the ExhaustiveFeatureSelector object\n",
    "# efs = efs.fit(df.DataFrame(x.values, columns=x.columns), y.values)\n",
    "\n",
    "# # Step 7: Retrieve the best feature subset\n",
    "# best_features = X.columns[list(efs.best_idx_)]\n",
    "# print('Best features:', best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a4d264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n",
    "\n",
    "# lasso = Lasso()\n",
    "# alphas = np.logspace(-4, -0.5, 30)\n",
    "\n",
    "# scores = []\n",
    "# for alpha in alphas:\n",
    "#     lasso.alpha = alpha\n",
    "#     score = np.mean(cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error'))\n",
    "#     scores.append(score)\n",
    "\n",
    "# ranked_features = np.argsort(-np.abs(scores))\n",
    "# for i in ranked_features:\n",
    "#     print(f'Feature {i}: {scores[i]}')\n",
    "\n",
    "# # Print 'Done' when finished\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02d9c841",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # Perform data preprocessing (e.g., scaling, one-hot encoding, etc.) as necessary\n",
    "\n",
    "# # Create the Lasso model\n",
    "# lasso = Lasso()\n",
    "# print('Done 1')\n",
    "\n",
    "# # Define the range of alpha values to test\n",
    "# alphas = np.logspace(-4, -0.5, 30)\n",
    "# print('Done 2')\n",
    "# print(dir(rfecv))\n",
    "\n",
    "# # Perform the recursive feature elimination with cross-validation\n",
    "# rfecv = RFECV(estimator=lasso, cv=KFold(n_splits=5, shuffle=True), scoring='accuracy')\n",
    "# print('Done 3')\n",
    "\n",
    "# try:\n",
    "#     rfecv.fit(X, y)\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "    \n",
    "# print('Done 4')\n",
    "\n",
    "# # # Print the optimal number of features and the selected features\n",
    "# print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "# print(\"Selected features: \", X.columns[rfecv.support_])\n",
    "\n",
    "# print('Done 5')\n",
    "\n",
    "# # Print 'Done' when finished\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b89f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoCV\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.feature_selection import RFECV\n",
    "\n",
    "# lasso = LassoCV(cv=5)\n",
    "\n",
    "# rfecv = RFECV(estimator=lasso, step=1, cv=KFold(5))\n",
    "\n",
    "# rfecv.fit(X, y)\n",
    "\n",
    "# print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "# # Get the column names of the selected features\n",
    "# selected_features = X_train.columns[rfecv.support_]\n",
    "\n",
    "# # Print the names of the selected features\n",
    "# print(\"Selected features: \", selected_features)\n",
    "\n",
    "# # print(\"Selected features: \", X.columns[rfecv.support_])\n",
    "\n",
    "# # Print 'Done' when finished\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8a9a305",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# # Perform feature selection using Lasso regularization with 5-fold cross-validation\n",
    "# lasso = Lasso(alpha=0.01, max_iter=10000)\n",
    "# scores = []\n",
    "# for i in range(X.shape[1]):\n",
    "#     score = cross_val_score(lasso, X[:, i:i+1], y, cv=5, scoring='accuracy').mean()\n",
    "#     scores.append(score)\n",
    "\n",
    "# # Rank the features based on their cross-validation scores\n",
    "# ranked_features = sorted(zip(scores, range(X.shape[1])), reverse=True)\n",
    "# selected_features = [f[1] for f in ranked_features[:10]] # Select the top 10 features\n",
    "\n",
    "# # Subset the dataset with the selected features\n",
    "# X_selected = X[:, selected_features]\n",
    "\n",
    "# # Print 'Done' when finished\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad643ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:47:48.048059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 14:47:52.697184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-22 14:47:52.697215: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-22 14:48:04.022032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 14:48:04.022220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 14:48:04.022241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Preprocess the data and split it into training and validation sets\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ...\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define the model architecture\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[43mnum_features\u001b[49m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Add convolutional layers to extract spatial features\u001b[39;00m\n\u001b[1;32m     16\u001b[0m conv1 \u001b[38;5;241m=\u001b[39m Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_features' is not defined"
     ]
    }
   ],
   "source": [
    "# The CNN-MLP Model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Preprocess the data and split it into training and validation sets\n",
    "# ...\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = Input(shape=(num_features, 1))\n",
    "\n",
    "# Add convolutional layers to extract spatial features\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "conv2 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv2)\n",
    "conv3 = Conv1D(filters=128, kernel_size=3, activation='relu')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "# Flatten the output of the convolutional layers to pass to the MLP layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add fully connected layers to classify the data\n",
    "dense1 = Dense(256, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(128, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)\n",
    "dense3 = Dense(num_classes, activation='softmax')(dropout2)\n",
    "\n",
    "# Define the model inputs and outputs\n",
    "model = Model(inputs=inputs, outputs=dense3)\n",
    "\n",
    "# Compile the model and define the loss function and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# # Print 'Done' when finished\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8d208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
